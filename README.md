# TextCNN 모델을 활용한 갈등 인지
**일반적인 갈등 맥락을 인지하는 딥러닝 모델**

2021년 Sungshin_3F 경진대회에서 웹툰 추천 알고리즘에 대해 설명할 때
'자극이 두드러지는 작품을 선호하시나요?'라는 질문에 대해 또래 평가에서
'**자극의 기준**이 무엇인가요?'라는 질문을 받았던 경험이 있습니다.

**의도했던 자극의 정의는 인물 간의 의견 충돌 혹은 다툼**이었는데,
자극의 기준으로 이 외에도 **선정성, 말 그대로의 아픔 등 유저들이 받아들이는 의의가 다를 수 있다**는 점을 깨달았습니다. 이를 보완하고자 딥러닝 모델 프로젝트를 진행하게 되었습니다.

TextCNN을 채택하게 된 이유로는 웹툰 댓글은 길이가 짧고, 그 특징을 추출하는 것이 중요하다고 생각했기 때문입니다.

"**인물 사이에 자극적인 장면이 많은 작품을 선호하시나요?**"
로 질문을 바꾸고, TextCNN 모델의 결과를 기준으로 **변수에 해당하는 웹툰 작품들을 재배열**하였습니다. **10명을 대상으로 파일럿 스터디**하여 다시 한번 테스트해본 결과 **초기 애플리케이션에서는 정확도가 60%였던 것이, 80%까지 상승**하는 결과를 얻을 수 있었습니다.

## 📌 데이터셋 구성

추천 대상이 되는 15개의 웹툰의 10화까지 베스트댓글 15개를. 수집 갈등의 표현을 잘 드러내고 있는 텍스트 데이터 100개를 txt 파일로 제작

- **OKT 형태소 분석기로 문장 분해**
- **위의 결과와 KNU 감정 사전을 매칭시켜 감정 점수 계산**
- **계산 결과에 따라 0보다 크면 일반 맥락(0), 0보다 같거나 작으면 갈등 맥락(1)으로 라벨링**

## 📌 딥러닝 모델이 한글을 학습할 수 있도록 데이터셋을 변환
문자를 숫자로 변환하여 컴퓨터가 인식하도록 해야 하는데, 단어나 문장을 벡터로 변환하여 벡터로 끼워넣는 과정을 word embedding(단어 임베딩)이라고 함. 분산 표현을 통해 여러 차원이 조합되어 의미적 유사도를 구할 수 있음.
이 프로젝트에서는 Word2Vec 임베딩을 사용

처음에 '차원'이라는 개념이 어려웠는데, 'I love you'를 예시로 들어보면 I=[1, 0, 0], love=[0, 1, 0], you=[0, 0, 1]의 벡터(행렬)로 나타낼 수 있음. 아래와 같이 중심 단어에 대한 벡터와 주변 단어에 대한 벡터를 교차하여 값을 계산하면 유사도를 파악하 수 있음.

![단어](https://github.com/SemiKwon/TextCNN/assets/76101347/00ba00db-ad49-47a5-83a3-22cb80c315ef)

Word2Vec은 중심 단어와 주변 단어를 통해 단어를 예측하는 방식. Word2Vec에는 두 가지 방법이 있는데 그중 Skip-gram을 선택했음. Skip-gram은 중심 단어에서 주변 단어를 예측하는 방식

![skipgram_dataset](https://github.com/SemiKwon/TextCNN/assets/76101347/4b5fc202-11cc-46f6-867f-9f3ecb5060a0)

![word2vec_renew_6](https://github.com/SemiKwon/TextCNN/assets/76101347/16e929a4-2c67-4acc-802b-f60d46418cf1)

출처 : https://wikidocs.net/22660

## 📌 TextCNN 모델

**1) TextCNN이란?**
* CNN → 이미지 처리 시 스캔하면서 특징을 추출 / TextCNN은 filter가 문장 스캔 → 문맥적 의미 파악 (정보 집약-연산속도 향상-분류 문제에서 좋은 결과) 
* 워드 임베딩 벡터를 입력값으로 투입 → Convolution 연산을 통해 feature map 생성 → 활성화 함수를 통해 feature map을 activation map으로 대응 → max-pooling → 결과를 fully-connected layer의 입력값으로 넣은 뒤 최종 분류

![다운로드](https://github.com/SemiKwon/TextCNN/assets/76101347/8af3323a-5f1f-4c8f-aaf5-2c5d088a5a8d)
)

출처 : IMPLEMENTING A CNN FOR TEXT CLASSIFICATION IN TENSORFLOW

![화면 캡처 2023-07-05 223117](https://github.com/SemiKwon/TextCNN/assets/76101347/68727ecb-61a9-4ebe-91b3-b56a66ea19f2)

위 사진의 구조로 의도한 모델을 설명하자면 다음과 같습니다.

* Input : row = 단어의 개수, column = 임베딩 차원
* 영역의 크기가 각각 2, 3, 4인 2개의 필터, 즉 6개의 필터를 통과
* 6X2, 5X2, 4X2 크기의 feature map이 생성 → 사전에 정의한 채널 수 만큼 생성(2)
* feature map이 activation map으로 변환, 가장 큰 값을 추출하는 max pooling을 통과
* 선택된 부분들이 concat되어 하나의 fully connected layer(single feature vector)를 형성
* softmax를 거쳐 최종적으로 두 클래스로 분류

출처 :  A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification 

## 📌 프로젝트 대입 결과
* ReLU, Dropout=0.5, train data=0.2, validation data=0.8, epoch=20
* epoch 1에서는 train:41.9%, valid:65%였지만, 최종 epoch 20에서는 train:100%, valid:95%를 확인할 수 있었습니다.
* test data에 대입할 때에도 내 의도와 모델이 판단한 결과가 거의 일치했습니다.
  * 다소 반어적인 표현 '명이 참 예쁜데 머리가 꽃밭인가봐.'와 같은 댓글도 갈등 맥락으로 인지할 수 있었습니다.

## 📌 어려운 점 
softmax 함수는 이진 분류가 아닌 확률 분포에 따른 분류를 해준다고 생각했었습니다. 따라서 왜 이진 분류인데, sigmoid가 쓰이지 않는가에 대해 의문을 가지며 sigmoid로 먼저 모델을 구상해보았는데요, 철저히 실패했습니다. 학습률이 늘어나지 않았고, 고여 있어 test data 또한 구분해내지 못했습니다.

그 이유를 생각해보니 단어 벡터를 연산하여 얻은 확률 분포로 갈등 맥락을 인지하는 모델의 메커니즘에서 sigmoid 함수로 분류할 때 적절하지 않은 결과가 도출된 것이었습니다. 그 후로 softmax로 바꾸어 적절한 출력 결과를 얻을 수 있었습니다. 
 
## 📌 개선점
* 많은 데이터 필요
* 앱에 적용하는 방법을 찾지 못함.

이전 프로젝트들을 통해 데이터 정제가 얼마나 중요한지를 알고 있습니다. 댓글의 경우 완전히 맞춤법을 지킨 경우가 거의 없었기에 이런 부분들을 하나 하나 다시 재생성하는 것이 어려웠습니다. 그래서 예상보다 이를 어느 정도 맞춤법에 맞게 변환하는 데 시간이 많이 들었습니다. 솔직히 의도한 결과가 나왔기 때문에 데이터셋을 더 모을 생각을 하지 않았지만, 완전히 일반화되기 위해서는 데이터가 훨씬 많이 약 10,000개 정도 필요하지 않을까 사려됩니다.

앱에 적용하는 방법, 즉 jupyter와 kotlin에 호환시키는 방법은 찾지 못했습니다. 아무래도 이 부분을 더 많이 공부하면 방법을 찾을 수 있을 것이라고 생각됩니다.
